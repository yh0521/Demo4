html
<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="AndroidWorld: A Dynamic Benchmarking Environment for Autonomous Agents">
  <meta name="keywords" content="Autonomous Agents, Benchmarking, Android, AI, Machine Learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>AndroidWorld: A Dynamic Benchmarking Environment for Autonomous Agents</title>

  <script type="module" src="https://md-block.verou.me/md-block.js"></script>

  <!-- Load d3.js -->
  <script src="https://d3js.org/d3.v4.js"></script>

  <!-- Load plotly.js -->
  <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>

  <!-- Color palette -->
  <script src="https://d3js.org/d3-scale-chromatic.v1.min.js"></script>

  <script src="https://cdn.jsdelivr.net/npm/d3plus-text@1"></script>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-MZNP3SCQ1V"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-MZNP3SCQ1V');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
</head>

<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-widescreen">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">AndroidWorld: A Dynamic Benchmarking Environment for Autonomous Agents</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                Christopher Rawles*, Sarah Clinckemaillie†, Yifan Chang†, Jonathan Waltz, Gabrielle Lau, Marybeth Fair, Alice Li, William Bishop, Wei Li, Folawiyo Campbell-Ajala, Daniel Toyama, Robert Berry, Divya Tyamagundlu, Timothy Lillicrap, Oriana Riva
              </span>
            </div>
            <br>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                Google DeepMind, Google
              </span>
            </div>
            <i style="font-size: 15px !important;">*Lead contributor. Contact: crawles@google.com</i>
            <i style="font-size: 15px !important;">†Equal contribution.</i>
          </div>
        </div>
      </div>
    </div>
  </section>
  <section>
    <div class="container is-max-widescreen">
      <h2 class="title">Abstract</h2>
      <p>Autonomous agents that execute human tasks by controlling computers can enhance human productivity and application accessibility. However, progress in this field will be driven by realistic and reproducible benchmarks. We present AndroidWorld, a fully functional Android environment that provides reward signals for 116 programmatic tasks across 20 real-world Android apps. Unlike existing interactive environments, which provide a static test set, AndroidWorld dynamically constructs tasks that are parameterized and expressed in natural language in unlimited ways, thus enabling testing on a much larger and more realistic suite of tasks. To ensure reproducibility, each task includes dedicated initialization, success-checking, and tear-down logic, which modifies and inspects the device's system state.</p>
      <p>We experiment with baseline agents to test AndroidWorld and provide initial results on the benchmark. Our best agent can complete 30.6% of AndroidWorld's tasks, leaving ample room for future work. Furthermore, we adapt a popular desktop web agent to work on Android, which we find to be less effective on mobile, suggesting future research is needed to achieve universal, cross-platform agents. Finally, we also conduct a robustness analysis, showing that task variations can significantly affect agent performance, demonstrating that without such testing, agent performance metrics may not fully reflect practical challenges. AndroidWorld and the experiments in this paper are available at <a href="https://github.com/google-research/android_world">https://github.com/google-research/android_world</a>.</p>
    </div>
  </section>
  <section>
    <div class="container is-max-widescreen">
      <h2 class="title">Introduction</h2>
      <p>Autonomous agents that interpret natural language instructions and operate computing devices can provide enormous value to users by automating repetitive tasks, augmenting human intelligence, and accomplishing complex workflows. However, a key research challenge remains the realistic evaluation of these agents in real-world settings. Despite growing enthusiasm for building autonomous agents, most existing approaches for evaluation compare an agent's actions at each step to a previously collected human demonstration. Measuring performance in this way can be misleading because when performing tasks online in real environments agents can take multiple paths to solve tasks, environments may behave non-deterministically, and agents can dynamically learn from mistakes to correct their actions. For this reason, online evaluation of agents in realistic environments able to reward task outcome provides a gold standard for evaluation. While there is an emerging body of work to address this need across different environments, there is no comprehensive solution for mobile platforms, such as Android, which are used by billions of users and therefore represent environments in which automation agents may be very productively employed. We introduce AndroidWorld to address this.</p>
      <div style="text-align: center;">
        <img src="./static/images/figure1_new.pdf" alt="AndroidWorld Architecture" width="95%">
        <p>Figure 1: AndroidWorld is an environment for building and testing autonomous agents.</p>
      </div>
    </div>
  </section>
  <section>
    <div class="container is-max-widescreen">
      <h2 class="title">Methods</h2>
      <p>AndroidWorld offers a reliable means of obtaining reward signals for tasks performed by agents in realistic mobile environments. Reward signals are quantitative metrics that indicate functional correctness of a task, i.e. is the stated goal achieved? For example, for the task "Send a text message to Jane confirming I'll be there," a positive reward indicates that the relevant message has been sent. Unlike simulated environments or games, real-world apps and websites do not inherently offer explicit reward signals. While human or LLM-based judges can be employed to reward the outcome of a task, these approaches scale poorly or are not fully reliable, respectively. Alternatively, environments for autonomous agents which provide automated ground-truth rewards for complex workflows have been developed. We find two problems with these environments. First, they are constrained to desktop computing environments, overlooking the mobile domain, which is of paramount importance given the ubiquity and diversity of mobile devices in the real world. Secondly, they are limited in their real-world diversity and scale. Crucially, unlike in real-world scenarios where conditions and task inputs vary widely, these environments support only static test specifications, meaning that when task parameters deviate, the reward signal is likely to break.</p>
    </div>
  </section>
  <section>
    <div class="container is-max-widescreen">
      <h2 class="title">Experimental Results</h2>
      <p>To demonstrate AndroidWorld's usefulness as a benchmark, we build and release a multi-modal agent, M3A (Multimodal Autonomous Agent for Android), and establish state-of-the-art results on AndroidWorld. We analyze M3A's performance using both multimodal and text-only input, and we observe that while multimodal perception can improve performance in some cases, it generally does not outperform the text-only approach. On AndroidWorld, M3A achieves a 30.6% success rate, which surpasses that of a web agent adapted for Android but remains significantly lower than the human success rate of 80.0%. In pursuit of building robust UI control agents, our study includes comprehensive tests under varied real-world conditions, demonstrating significant performance variations primarily driven by changes in intent parameters.</p>
    </div>
  </section>
  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="https://github.com/google-research/android_world" class="external-link">
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              This means you are free to borrow the <a href="https://github.com/google-research/android_world">source
                code</a> of this website (the website is hosted on the gh-pages branch of the repository),
              we just ask that you link back to this page in the footer.
              The design of this website is based on <a href="https://nerfies.github.io/">NERFies</a> ,<a
                href="https://ds1000-code-gen.github.io/" target="_blank">DS-1000</a> and <a
                href="https://webshop-pnlp.github.io/" target="_blank">WebShop</a>. Please
              remember to remove the analytics code included in the header of the website which you do not want on
              your website. </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>